{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os  # For file and directory operations\n",
    "import pickle  # For loading CIFAR-10 data files\n",
    "import numpy as np  # For numerical operations\n",
    "import torch  # PyTorch deep learning framework\n",
    "import torch.nn as nn  # Neural network modules\n",
    "import torch.nn.functional as F  # Neural network functions\n",
    "from torch.utils.data import Dataset, DataLoader, random_split  # Dataset handling\n",
    "import torchvision.transforms as transforms  # Image transformations\n",
    "import torch.optim as optim  # Optimization algorithms\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "from tqdm import tqdm  # Progress bar\n",
    "import random  # Random number generation\n",
    "from torch.optim.swa_utils import AveragedModel  # Stochastic Weight Averaging\n",
    "import math  # Mathematical functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ----- Device configuration (CPU/MPS/GPU) -----\n",
    "# Check available hardware and set device accordingly\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Apple Silicon GPU\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # NVIDIA GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # CPU\n",
    "print(f\"Using device: {device} for model training and inference\")\n",
    "\n",
    "# Set seed for reproducibility across runs\n",
    "print(\"Setting random seeds for reproducibility...\")\n",
    "SEED = 42\n",
    "random.seed(SEED)  # Python random\n",
    "np.random.seed(SEED)  # NumPy random\n",
    "torch.manual_seed(SEED)  # PyTorch random\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)  # GPU random\n",
    "    # Enable deterministic GPU operations\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "print(f\"Random seeds set to {SEED}\")\n",
    "\n",
    "def get_mean_std(dataset):\n",
    "    \"\"\"\n",
    "    Calculate mean and standard deviation of a dataset.\n",
    "    Important for normalizing the data properly.\n",
    "    \n",
    "    Args:\n",
    "        dataset: PyTorch dataset object\n",
    "    Returns:\n",
    "        mean: Mean of the dataset\n",
    "        std: Standard deviation of the dataset\n",
    "    \"\"\"\n",
    "    print(\"Calculating dataset statistics...\")\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    total_images = 0\n",
    "    \n",
    "    for images, _ in loader:\n",
    "        batch_size = images.size(0)\n",
    "        images = images.view(batch_size, -1)\n",
    "        mean += images.mean(1).sum().item()\n",
    "        std += images.std(1).sum().item()\n",
    "        total_images += batch_size\n",
    "    \n",
    "    mean /= total_images\n",
    "    std /= total_images\n",
    "    \n",
    "    print(f\"Dataset statistics - Mean: {mean:.4f}, Std: {std:.4f}\")\n",
    "    return mean, std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load CIFAR-10 Training Data with Optimized Handling\n",
    "\n",
    "This section handles loading and preprocessing of CIFAR-10 training data:\n",
    "- Loads data from 5 separate batch files for memory efficiency\n",
    "- Reshapes data into NCHW format (N=samples, C=channels, H=height, W=width)\n",
    "- Combines batches into unified training set\n",
    "- Performs data validation and prints detailed statistics\n",
    "\n",
    "Key optimizations:\n",
    "- Direct reshape to NCHW format to avoid extra transpose operations\n",
    "- Batch-wise loading to manage memory usage\n",
    "- Efficient numpy array operations for data combination\n",
    "\n",
    "Expected output:\n",
    "- 50,000 training images in (N, 3, 32, 32) format\n",
    "- Labels as 1D array of integers 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    \"\"\"\n",
    "    Load CIFAR-10 data from pickle files efficiently.\n",
    "    \n",
    "    Args:\n",
    "        file: Path to pickle file\n",
    "    Returns:\n",
    "        Dictionary containing batch data\n",
    "    \"\"\"\n",
    "    print(f\"Loading file: {file}\")\n",
    "    with open(file, 'rb') as fo:\n",
    "        data_dict = pickle.load(fo, encoding='bytes')\n",
    "    return data_dict\n",
    "\n",
    "def load_data(data_dir=\"./data/cifar-10-python/cifar-10-batches-py\"):\n",
    "    \"\"\"\n",
    "    Load and combine all CIFAR-10 training batches.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing CIFAR-10 data files\n",
    "    Returns:\n",
    "        all_data: Combined training images\n",
    "        all_labels: Combined training labels\n",
    "    \"\"\"\n",
    "    print(\"Starting CIFAR-10 data loading process...\")\n",
    "    data_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for i in range(1, 6):  # CIFAR-10 has 5 training batches\n",
    "        batch_file = os.path.join(data_dir, f\"data_batch_{i}\")\n",
    "        batch = unpickle(batch_file)\n",
    "        data = batch[b\"data\"]\n",
    "        labels = batch[b\"labels\"]\n",
    "        \n",
    "        # Reshape data to (N, C, H, W) format directly for efficiency\n",
    "        data = data.reshape(-1, 3, 32, 32)\n",
    "        \n",
    "        data_list.append(data)\n",
    "        labels_list.extend(labels)\n",
    "        print(f\"Loaded batch {i}: data shape {data.shape}, labels count {len(labels)}\")\n",
    "    \n",
    "    all_data = np.concatenate(data_list, axis=0)\n",
    "    all_labels = np.array(labels_list)\n",
    "    \n",
    "    print(f\"Total dataset loaded - Shape: {all_data.shape}, Labels: {all_labels.shape}\")\n",
    "    return all_data, all_labels\n",
    "\n",
    "# Load the training data\n",
    "print(\"Loading CIFAR-10 training data...\")\n",
    "all_data, all_labels = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Enhanced Data Augmentation and Transforms\n",
    "This section implements advanced data augmentation techniques to:\n",
    "1. Improve model generalization by exposing it to diverse image variations\n",
    "2. Reduce overfitting by artificially expanding the training dataset\n",
    "3. Make the model more robust to real-world variations in images\n",
    "\n",
    "Key augmentation techniques used:\n",
    "- Random cropping: For translation invariance\n",
    "- Horizontal flips: For orientation invariance  \n",
    "- AutoAugment: For automated policy-based augmentations\n",
    "- Random erasing: For occlusion robustness\n",
    "- Normalization: For stable training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nConfiguring data augmentation pipeline...\")\n",
    "print(\"Implementing the following augmentation techniques:\")\n",
    "print(\"- Random cropping with padding=4\")\n",
    "print(\"- Random horizontal flips\")\n",
    "print(\"- CIFAR10-specific AutoAugment policies\") \n",
    "print(\"- Random erasing with p=0.25\")\n",
    "print(\"- Standard CIFAR10 normalization\")\n",
    "# CIFAR-10 standard mean and std values for normalization\n",
    "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
    "cifar10_std = (0.2470, 0.2435, 0.2616)\n",
    "\n",
    "# Advanced training transforms for better model generalization\n",
    "print(\"Setting up data augmentation pipelines...\")\n",
    "train_transform = transforms.Compose([\n",
    "    lambda x: x / 255.0,  # Normalize pixel values to [0, 1]\n",
    "    transforms.RandomCrop(32, padding=4),  # Random crops for translation invariance\n",
    "    transforms.RandomHorizontalFlip(),  # Horizontal flips for orientation invariance\n",
    "    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),  # AutoAugment for robust training\n",
    "    transforms.Normalize(cifar10_mean, cifar10_std),  # Standardize using CIFAR-10 statistics\n",
    "    transforms.RandomErasing(p=0.25),  # Random erasing for occlusion robustness\n",
    "])\n",
    "\n",
    "# Minimal test/validation transforms - only essential normalization\n",
    "test_transform = transforms.Compose([\n",
    "    lambda x: x / 255.0,\n",
    "    transforms.Normalize(cifar10_mean, cifar10_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Improved Dataset and DataLoader for Training/Validation\n",
    "This section implements optimized data handling and loading with:\n",
    "1. Custom Dataset class for efficient memory usage and fast access\n",
    "2. Strategic train/validation split for proper model evaluation\n",
    "3. Optimized DataLoader configuration for maximum throughput\n",
    "4. Careful batch size selection for stable training\n",
    "\n",
    "Key optimizations:\n",
    "- Parallel data loading with multiple workers\n",
    "- Pinned memory for faster GPU transfer\n",
    "- Persistent workers to reduce overhead\n",
    "- Different batch sizes for train vs validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\\nSetting up optimized data pipeline...\")\n",
    "print(\"Implementing the following optimizations:\")\n",
    "print(\"- Custom Dataset class for efficient data handling\")\n",
    "print(\"- 90/10 train-validation split for proper evaluation\")\n",
    "print(\"- Multi-worker data loading for better throughput\")\n",
    "print(\"- Pinned memory and persistent workers for faster processing\")\n",
    "print(\"- Optimized batch sizes: 128 for training, 256 for validation\")\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class for CIFAR-10 with efficient data handling\n",
    "    \"\"\"\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = torch.from_numpy(image).float()  # Convert to PyTorch tensor\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "print(\"Creating datasets and dataloaders...\")\n",
    "# Create the main dataset\n",
    "dataset = CIFAR10Dataset(all_data, all_labels, transform=train_transform)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = 45000  # 90% for training\n",
    "val_size = len(dataset) - train_size  # 10% for validation\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset, \n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)  # Ensure reproducible splits\n",
    ")\n",
    "\n",
    "# Update validation transform to test transform\n",
    "val_dataset.dataset.transform = test_transform\n",
    "\n",
    "# Create optimized dataloaders\n",
    "print(\"Configuring dataloaders with optimized settings...\")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=128,  # Balanced batch size for training\n",
    "    shuffle=True,  # Shuffle training data\n",
    "    num_workers=4,  # Parallel data loading\n",
    "    pin_memory=True,  # Faster data transfer to GPU\n",
    "    persistent_workers=True  # Keep workers alive between epochs\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=256,  # Larger batches for validation (no backprop needed)\n",
    "    shuffle=False,  # No need to shuffle validation data\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Advanced Augmentation and Loss Functions\n",
    "This step implements sophisticated data augmentation and loss techniques:\n",
    "1. CutMix - Combines portions of different images and their labels\n",
    "2. Mixup - Linearly interpolates between pairs of images and labels\n",
    "3. Label smoothing - Reduces overconfidence by softening one-hot labels\n",
    "4. Adaptive loss weighting - Dynamically adjusts loss contributions\n",
    "\n",
    "These techniques help:\n",
    "- Improve model generalization by creating diverse training samples\n",
    "- Reduce overfitting by introducing regularization effects\n",
    "- Make training more robust to noisy labels and outliers\n",
    "- Encourage the model to learn more meaningful features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Setting up advanced augmentation and loss functions...\")\n",
    "\n",
    "# CutMix augmentation - Combines portions of images and their labels\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Implements CutMix augmentation by cutting and pasting random patches between images.\n",
    "    This helps the model learn more robust features by seeing partial objects.\n",
    "    \n",
    "    Args:\n",
    "        x: Input images tensor\n",
    "        y: Labels tensor \n",
    "        alpha: Beta distribution parameter for mixing ratio\n",
    "    Returns:\n",
    "        Mixed images and corresponding mixed labels\n",
    "    \"\"\"\n",
    "    print(\"Applying CutMix augmentation...\")\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)  # Sample mixing ratio from beta distribution\n",
    "    else:\n",
    "        lam = 1\n",
    "    \n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(device)  # Random permutation for mixing\n",
    "    \n",
    "    y_a, y_b = y, y[index]  # Original and permuted labels\n",
    "    \n",
    "    # Generate random bounding box coordinates\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]  # Patch mixing\n",
    "    \n",
    "    # Adjust lambda to match actual mixed pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "    \n",
    "    return x, y_a, y_b, lam\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    \"\"\"\n",
    "    Generate random bounding box coordinates for CutMix.\n",
    "    \n",
    "    Args:\n",
    "        size: Input tensor size\n",
    "        lam: Target ratio of remaining area\n",
    "    Returns:\n",
    "        Bounding box coordinates\n",
    "    \"\"\"\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)  # Cut ratio\n",
    "    cut_w = np.int64(W * cut_rat)  # Cut width\n",
    "    cut_h = np.int64(H * cut_rat)  # Cut height\n",
    "    \n",
    "    # Random center point\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "    \n",
    "    # Ensure coordinates are within image bounds\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    \n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "# Mixup augmentation - Linearly combines pairs of images and labels\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Implements Mixup augmentation by linearly interpolating between pairs of images.\n",
    "    This helps reduce overconfidence and improve generalization.\n",
    "    \n",
    "    Args:\n",
    "        x: Input images tensor\n",
    "        y: Labels tensor\n",
    "        alpha: Beta distribution parameter\n",
    "    Returns:\n",
    "        Mixed images and corresponding mixed labels\n",
    "    \"\"\"\n",
    "    print(\"Applying Mixup augmentation...\")\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)  # Mixing coefficient\n",
    "    else:\n",
    "        lam = 1\n",
    "    \n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(device)  # Random permutation\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]  # Linear interpolation of images\n",
    "    y_a, y_b = y, y[index]  # Original and permuted labels\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"\n",
    "    Criterion for Mixup that combines losses with same ratio as images.\n",
    "    \n",
    "    Args:\n",
    "        criterion: Base loss function\n",
    "        pred: Model predictions\n",
    "        y_a, y_b: Original and permuted labels\n",
    "        lam: Mixing ratio\n",
    "    Returns:\n",
    "        Combined loss value\n",
    "    \"\"\"\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "def update_bn_custom(loader, model, device):\n",
    "    \"\"\"\n",
    "    Updates BatchNorm statistics properly with device handling.\n",
    "    Important for SWA and model evaluation.\n",
    "    \n",
    "    Args:\n",
    "        loader: DataLoader for computing statistics\n",
    "        model: Model containing BatchNorm layers\n",
    "        device: Device for computation\n",
    "    \"\"\"\n",
    "    print(\"Updating BatchNorm statistics...\")\n",
    "    momenta = {}\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "            module.running_mean = torch.zeros_like(module.running_mean, device=device)\n",
    "            module.running_var = torch.ones_like(module.running_var, device=device)\n",
    "            momenta[module] = module.momentum\n",
    "            module.momentum = None\n",
    "            module.num_batches_tracked *= 0\n",
    "    \n",
    "    model.train()\n",
    "    with torch.no_grad():\n",
    "        for data, _ in loader:\n",
    "            data = data.to(device)\n",
    "            model(data)\n",
    "    \n",
    "    for module in momenta.keys():\n",
    "        module.momentum = momenta[module]\n",
    "\n",
    "# Advanced label smoothing with focal loss component\n",
    "class FocalLabelSmoothing(nn.Module):\n",
    "    \"\"\"\n",
    "    Combines label smoothing with focal loss for better handling of hard examples.\n",
    "    \n",
    "    Args:\n",
    "        classes: Number of classes\n",
    "        smoothing: Label smoothing factor\n",
    "        gamma: Focal loss power factor\n",
    "    \"\"\"\n",
    "    def __init__(self, classes=10, smoothing=0.1, gamma=1.0):\n",
    "        super(FocalLabelSmoothing, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.classes = classes\n",
    "        self.gamma = gamma\n",
    "        print(f\"Initialized Focal Label Smoothing with gamma={gamma}\")\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=-1)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.classes - 1))\n",
    "            true_dist.scatter_(1, target.unsqueeze(1), self.confidence)\n",
    "        \n",
    "        pt = torch.exp(pred)  # Probability of true class\n",
    "        focal_weight = (1 - pt) ** self.gamma  # Higher weight for hard examples\n",
    "        \n",
    "        return torch.mean(torch.sum(-true_dist * pred * focal_weight, dim=-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Advanced ResNet Model with SE Blocks and Bottleneck\n",
    "\n",
    "This section implements an enhanced ResNet architecture with:\n",
    "1. Squeeze-and-Excitation (SE) blocks for adaptive feature recalibration\n",
    "   - Helps model focus on informative features\n",
    "   - Improves accuracy with minimal parameter overhead\n",
    "\n",
    "2. Bottleneck blocks for efficient feature processing\n",
    "   - Reduces computational cost while maintaining performance\n",
    "   - Better gradient flow through the network\n",
    "\n",
    "3. Skip connections for improved gradient flow\n",
    "   - Allows training of very deep networks\n",
    "   - Helps combat vanishing gradients\n",
    "\n",
    "The architecture is carefully designed to:\n",
    "- Stay within the 5M parameter budget\n",
    "- Maximize accuracy through modern techniques\n",
    "- Maintain efficient training and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Initializing model architecture...\")\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation block for channel attention.\n",
    "    Helps model focus on informative features by learning channel interdependencies.\n",
    "    \n",
    "    Args:\n",
    "        channels: Number of input channels\n",
    "        reduction: Channel reduction ratio\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, reduction=8):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)  # Global average pooling\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x  # Channel-wise multiplication\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic ResNet block with optional SE attention.\n",
    "    \n",
    "    Args:\n",
    "        in_channels: Input channels\n",
    "        out_channels: Output channels\n",
    "        stride: Convolution stride\n",
    "        use_se: Whether to use SE attention\n",
    "        se_reduction: SE block reduction ratio\n",
    "    \"\"\"\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, use_se=True, se_reduction=8):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Skip connection for dimension matching\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        \n",
    "        self.use_se = use_se\n",
    "        if use_se:\n",
    "            self.se = SEBlock(out_channels, reduction=se_reduction)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out, inplace=True)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.use_se:\n",
    "            out = self.se(out)\n",
    "            \n",
    "        out += self.shortcut(residual)  # Skip connection\n",
    "        out = F.relu(out, inplace=True)\n",
    "        return out\n",
    "\n",
    "class OptimizedResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Optimized ResNet architecture with SE attention and advanced features.\n",
    "    \n",
    "    Args:\n",
    "        block: Basic block class\n",
    "        num_blocks: Number of blocks per layer\n",
    "        initial_channels: Initial number of channels\n",
    "        num_classes: Number of output classes\n",
    "        use_se: Whether to use SE attention\n",
    "        se_reduction: SE block reduction ratio\n",
    "        drop_rate: Dropout rate\n",
    "    \"\"\"\n",
    "    def __init__(self, block, num_blocks, initial_channels=40, num_classes=10, \n",
    "                 use_se=True, se_reduction=8, drop_rate=0.2):\n",
    "        super(OptimizedResNet, self).__init__()\n",
    "        self.in_channels = initial_channels\n",
    "        self.drop_rate = drop_rate\n",
    "        \n",
    "        print(f\"Building OptimizedResNet with {sum(num_blocks)} blocks and SE attention\")\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, initial_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(initial_channels)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, initial_channels, num_blocks[0], stride=1, \n",
    "                                     use_se=use_se, se_reduction=se_reduction)\n",
    "        self.layer2 = self._make_layer(block, initial_channels*2, num_blocks[1], stride=2, \n",
    "                                     use_se=use_se, se_reduction=se_reduction)\n",
    "        self.layer3 = self._make_layer(block, initial_channels*4, num_blocks[2], stride=2, \n",
    "                                     use_se=use_se, se_reduction=se_reduction)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(initial_channels*4, num_classes)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "        print(\"Model initialization complete\")\n",
    "    \n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride, use_se, se_reduction):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride, use_se, se_reduction))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize model weights using Kaiming initialization\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        \n",
    "        out = self.avg_pool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        \n",
    "        if self.drop_rate > 0 and self.training:\n",
    "            out = F.dropout(out, p=self.drop_rate, training=self.training)\n",
    "            \n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count number of trainable parameters in the model\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Enhanced Training with Cosine Warmup and SWA\n",
    "\n",
    "This section implements advanced training techniques to improve model performance:\n",
    "\n",
    "1. Cosine Warmup Learning Rate Schedule\n",
    "   - Gradual warmup prevents unstable training at the start\n",
    "   - Cosine annealing helps find better optima\n",
    "   - Smooth transitions avoid sudden learning rate changes\n",
    "\n",
    "2. Stochastic Weight Averaging (SWA)\n",
    "   - Averages multiple points along the trajectory\n",
    "   - Leads to better generalization\n",
    "   - Acts as an effective model ensemble\n",
    "\n",
    "3. Exponential Moving Average (EMA)\n",
    "   - Maintains a moving average of model weights\n",
    "   - More stable than using final weights\n",
    "   - Often improves validation/test accuracy\n",
    "\n",
    "These techniques work together to:\n",
    "- Stabilize the training process\n",
    "- Improve model generalization\n",
    "- Achieve better final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Initializing advanced training components...\")\n",
    "\n",
    "# Learning rate scheduler with warmup\n",
    "class CosineWarmupScheduler:\n",
    "    \"\"\"\n",
    "    Custom learning rate scheduler that implements:\n",
    "    1. Linear warmup phase to avoid initial training instability\n",
    "    2. Cosine annealing for better convergence\n",
    "    \n",
    "    Args:\n",
    "        optimizer: The optimizer to adjust learning rates for\n",
    "        warmup_epochs: Number of epochs for linear warmup\n",
    "        max_epochs: Total number of training epochs\n",
    "        min_lr: Minimum learning rate\n",
    "        max_lr: Maximum learning rate after warmup\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, warmup_epochs, max_epochs, min_lr=1e-6, max_lr=0.1):\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.max_epochs = max_epochs\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        print(f\"Initialized scheduler with {warmup_epochs} warmup epochs, lr range: [{min_lr}, {max_lr}]\")\n",
    "        \n",
    "    def step(self, epoch):\n",
    "        if epoch < self.warmup_epochs:\n",
    "            # Linear warmup phase - gradually increase lr to avoid initial shock to the model\n",
    "            lr = self.min_lr + (self.max_lr - self.min_lr) * epoch / self.warmup_epochs\n",
    "        else:\n",
    "            # Cosine annealing phase - smoothly decrease lr for better convergence\n",
    "            progress = (epoch - self.warmup_epochs) / (self.max_epochs - self.warmup_epochs)\n",
    "            lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + math.cos(math.pi * progress))\n",
    "        \n",
    "        # Update learning rate for all parameter groups\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        \n",
    "        return lr\n",
    "\n",
    "# Exponential Moving Average (EMA) for model weights\n",
    "class EMA:\n",
    "    \"\"\"\n",
    "    Implements Exponential Moving Average for model weights.\n",
    "    EMA maintains a moving average of model parameters which typically \n",
    "    produces better validation/test accuracy than using final weights.\n",
    "    \n",
    "    Args:\n",
    "        model: The model whose parameters to track\n",
    "        decay: EMA decay rate (higher = slower but more stable)\n",
    "    \"\"\"\n",
    "    def __init__(self, model, decay=0.9999):\n",
    "        self.model = model\n",
    "        self.decay = decay\n",
    "        self.shadow = {}  # Shadow parameters\n",
    "        self.backup = {}  # Backup of original parameters\n",
    "        print(f\"Initialized EMA with decay rate {decay}\")\n",
    "        \n",
    "    def register(self):\n",
    "        \"\"\"Initialize EMA shadow parameters as copies of model parameters\"\"\"\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "        print(\"Registered initial model parameters in EMA\")\n",
    "    \n",
    "    def update(self):\n",
    "        \"\"\"Update shadow parameters using EMA decay rate\"\"\"\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                new_avg = self.decay * self.shadow[name] + (1 - self.decay) * param.data\n",
    "                self.shadow[name] = new_avg.clone()\n",
    "    \n",
    "    def apply_shadow(self):\n",
    "        \"\"\"Apply shadow parameters to model, saving original parameters\"\"\"\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.backup[name] = param.data\n",
    "                param.data = self.shadow[name]\n",
    "    \n",
    "    def restore(self):\n",
    "        \"\"\"Restore original parameters to model\"\"\"\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data = self.backup[name]\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=250):\n",
    "    \"\"\"\n",
    "    Main training loop implementing advanced training techniques including:\n",
    "    - SGD with Nesterov momentum and weight decay\n",
    "    - Focal Label Smoothing loss\n",
    "    - Cosine learning rate scheduling with warmup\n",
    "    - Exponential Moving Average (EMA) of model weights\n",
    "    - Stochastic Weight Averaging (SWA)\n",
    "    - Adaptive data augmentation (MixUp and CutMix)\n",
    "    - Gradient clipping\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model to train\n",
    "        train_loader: DataLoader for training data\n",
    "        val_loader: DataLoader for validation data\n",
    "        num_epochs: Number of training epochs\n",
    "        \n",
    "    Returns:\n",
    "        model: Trained model\n",
    "        swa_model: Stochastic Weight Averaged model\n",
    "        ema: EMA model instance\n",
    "        metrics: Tuple of (train_losses, train_accs, val_losses, val_accs)\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Initializing Training Components ===\")\n",
    "    \n",
    "    # Setup optimizer with Nesterov momentum and L2 regularization\n",
    "    print(\"Setting up SGD optimizer with Nesterov momentum...\")\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), \n",
    "        lr=0.1,  # Initial learning rate (will be adjusted by scheduler)\n",
    "        momentum=0.9,  # Momentum coefficient for faster convergence\n",
    "        weight_decay=5e-4,  # L2 regularization to prevent overfitting\n",
    "        nesterov=True  # Use Nesterov momentum for better convergence\n",
    "    )\n",
    "    \n",
    "    print(\"Configuring Focal Label Smoothing loss...\")\n",
    "    criterion = FocalLabelSmoothing(classes=10, smoothing=0.1, gamma=1.0)\n",
    "    \n",
    "    print(\"Setting up Cosine learning rate scheduler with warmup...\")\n",
    "    scheduler = CosineWarmupScheduler(\n",
    "        optimizer, \n",
    "        warmup_epochs=5,  # Gradual LR increase for 5 epochs\n",
    "        max_epochs=num_epochs,\n",
    "        min_lr=1e-6,  # Minimum LR at end of training\n",
    "        max_lr=0.1  # Maximum LR after warmup\n",
    "    )\n",
    "    \n",
    "    print(\"Initializing EMA model tracking...\")\n",
    "    ema = EMA(model, decay=0.9999)  # High decay for stability\n",
    "    ema.register()\n",
    "    \n",
    "    print(\"Creating SWA model for late-stage averaging...\")\n",
    "    swa_model = AveragedModel(model)\n",
    "    swa_start = int(num_epochs * 0.75)  # Start SWA at 75% of training\n",
    "    print(f\"SWA will begin at epoch {swa_start}\")\n",
    "    \n",
    "    # Initialize tracking metrics\n",
    "    best_val_acc = 0.0\n",
    "    train_losses, train_accs = [], []\n",
    "    val_losses, val_accs = [], []\n",
    "    \n",
    "    print(\"\\n=== Starting Training Loop ===\")\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Update learning rate using scheduler\n",
    "        current_lr = scheduler.step(epoch - 1)\n",
    "        print(f\"\\nEpoch {epoch}/{num_epochs} - Learning Rate: {current_lr:.6f}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs} [Train]\")\n",
    "        \n",
    "        for inputs, targets in train_pbar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Adaptive data augmentation strategy\n",
    "            aug_prob = random.random()\n",
    "            late_training = epoch >= int(num_epochs * 0.8)\n",
    "            \n",
    "            if aug_prob < 0.5 and not late_training:\n",
    "                # Apply MixUp with adaptive strength\n",
    "                mixup_strength = max(0.0, 0.4 * (1 - epoch / num_epochs))\n",
    "                inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, alpha=mixup_strength)\n",
    "                outputs = model(inputs)\n",
    "                loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "            elif aug_prob < 0.8 and not late_training:\n",
    "                # Apply CutMix with adaptive strength\n",
    "                cutmix_strength = max(0.0, 1.0 * (1 - epoch / num_epochs))\n",
    "                inputs, targets_a, targets_b, lam = cutmix_data(inputs, targets, alpha=cutmix_strength)\n",
    "                outputs = model(inputs)\n",
    "                loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "            else:\n",
    "                # Standard forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Optimization step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Prevent exploding gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update EMA model\n",
    "            ema.update()\n",
    "            \n",
    "            # Track metrics\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            # Calculate accuracy (adjusted for augmentation)\n",
    "            total += targets.size(0)\n",
    "            if aug_prob < 0.8 and not late_training:\n",
    "                correct += (lam * predicted.eq(targets_a).sum().float() + \n",
    "                          (1 - lam) * predicted.eq(targets_b).sum().float()).item()\n",
    "            else:\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            # Update progress display\n",
    "            train_pbar.set_postfix({\n",
    "                'loss': train_loss/total, \n",
    "                'acc': 100.0*correct/total,\n",
    "                'lr': current_lr\n",
    "            })\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        train_loss = train_loss / total\n",
    "        train_acc = 100.0 * correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        \n",
    "        # Update SWA model if in SWA phase\n",
    "        if epoch >= swa_start:\n",
    "            print(\"Updating SWA model parameters...\")\n",
    "            swa_model.update_parameters(model)\n",
    "        \n",
    "        # Validation phase\n",
    "        print(\"\\nRunning validation...\")\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch}/{num_epochs} [Val]\")\n",
    "            for inputs, targets in val_pbar:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = F.cross_entropy(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "                \n",
    "                val_pbar.set_postfix({\n",
    "                    'loss': val_loss/total, \n",
    "                    'acc': 100.0*correct/total\n",
    "                })\n",
    "        \n",
    "        val_loss = val_loss / total\n",
    "        val_acc = 100.0 * correct / total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        # Save best model checkpoints\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            print(f\"\\nNew best validation accuracy: {best_val_acc:.2f}%\")\n",
    "            print(\"Saving best model checkpoint...\")\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            \n",
    "            # Also save EMA model\n",
    "            print(\"Saving best EMA model checkpoint...\")\n",
    "            ema.apply_shadow()\n",
    "            torch.save(model.state_dict(), \"best_ema_model.pth\")\n",
    "            ema.restore()\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"\\nEpoch {epoch} Summary:\")\n",
    "        print(f\"Training - Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "        print(f\"Validation - Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "        print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "    \n",
    "    print(\"\\n=== Training Complete ===\")\n",
    "    \n",
    "    # Finalize SWA model\n",
    "    print(\"\\nUpdating BatchNorm statistics for SWA model...\")\n",
    "    with torch.no_grad():\n",
    "        update_bn_custom(train_loader, swa_model, device)\n",
    "    \n",
    "    print(\"Saving final SWA model...\")\n",
    "    torch.save(swa_model.state_dict(), \"swa_model.pth\")\n",
    "    \n",
    "    return model, swa_model, ema, (train_losses, train_accs, val_losses, val_accs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Enhanced Test Prediction with Ensemble of Best Models\n",
    "\n",
    "This section implements sophisticated prediction techniques to maximize accuracy:\n",
    "\n",
    "1. Model Ensemble Strategy\n",
    "   - Combines predictions from multiple trained models:\n",
    "     * Best validation model\n",
    "     * SWA model with updated BatchNorm stats  \n",
    "     * EMA model with smoothed weights\n",
    "   - Reduces prediction variance and improves robustness\n",
    "   - Each model contributes complementary features\n",
    "\n",
    "2. Test-Time Augmentation (TTA)\n",
    "   - Makes predictions on multiple augmented versions:\n",
    "     * Original image\n",
    "     * Horizontal flips \n",
    "     * Random scaling (0.8-1.2x)\n",
    "     * Center crops\n",
    "     * Brightness/contrast adjustments\n",
    "   - Averages predictions across variants\n",
    "   - More robust predictions by considering multiple views\n",
    "\n",
    "3. Optimized Data Pipeline\n",
    "   - Efficient batched processing\n",
    "   - GPU acceleration with pinned memory\n",
    "   - Parallel data loading with multiple workers\n",
    "   - Careful memory management\n",
    "\n",
    "The combination of these techniques helps:\n",
    "- Maximize prediction accuracy\n",
    "- Improve robustness to input variations  \n",
    "- Maintain efficient processing speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nInitializing enhanced prediction pipeline...\")\n",
    "print(\"Using ensemble of 3 models: Best Val, SWA, and EMA\")\n",
    "print(\"Applying test-time augmentation with multiple variants\")\n",
    "print(\"Optimizing for both accuracy and inference speed\")\n",
    "\n",
    "def predict_with_enhanced_tta(ensemble, test_loader, num_tta=5):\n",
    "    \"\"\"\n",
    "    Make predictions using model ensemble and test-time augmentation.\n",
    "    \n",
    "    This function:\n",
    "    1. Combines predictions from multiple models in the ensemble\n",
    "    2. Applies test-time augmentation including:\n",
    "       - Original image\n",
    "       - Horizontal flips\n",
    "       - Random scaling\n",
    "       - Center crops\n",
    "       - Brightness adjustments\n",
    "    3. Averages predictions across all variants for more robust results\n",
    "    \n",
    "    Args:\n",
    "        ensemble: List of trained models to use for prediction\n",
    "        test_loader: DataLoader for test data\n",
    "        num_tta: Number of additional TTA variants to use\n",
    "    Returns:\n",
    "        all_predictions: List of predicted class indices\n",
    "        all_ids: List of corresponding image IDs\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "    all_ids = []\n",
    "    \n",
    "    print(\"\\n=== Starting Enhanced Prediction with Ensemble and TTA ===\")\n",
    "    print(f\"Using ensemble of {len(ensemble)} models\")\n",
    "    print(f\"Applying {num_tta + 1} TTA variants per model\") # +1 for horizontal flip\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, image_ids) in enumerate(test_loader):\n",
    "            # Print batch info for verification\n",
    "            if batch_idx == 0:\n",
    "                print(f\"\\nProcessing first batch:\")\n",
    "                print(f\"Batch images shape: {images.shape}\")\n",
    "                print(f\"Device being used: {images.device}\")\n",
    "            \n",
    "            # Move batch to appropriate device\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Initialize prediction accumulator tensor\n",
    "            batch_size = images.size(0)\n",
    "            ensemble_probs = torch.zeros((batch_size, 10), device=device)\n",
    "            \n",
    "            # Process with each model in ensemble\n",
    "            for model_idx, model in enumerate(ensemble):\n",
    "                model.eval()\n",
    "                \n",
    "                # 1. Original image prediction\n",
    "                outputs = model(images)\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                ensemble_probs += probs\n",
    "                \n",
    "                # 2. Horizontal flip TTA - helps with orientation invariance\n",
    "                flipped_images = torch.flip(images, [3])\n",
    "                flip_outputs = model(flipped_images)\n",
    "                flip_probs = F.softmax(flip_outputs, dim=1)\n",
    "                ensemble_probs += flip_probs\n",
    "                \n",
    "                # 3. Additional TTA variants\n",
    "                for i in range(num_tta - 1):\n",
    "                    # Apply different transforms in rotation\n",
    "                    if i % 3 == 0:\n",
    "                        # Scale transform: Randomly scale image intensity\n",
    "                        # Helps with robustness to contrast variations\n",
    "                        transformed_images = images * (0.95 + 0.1 * torch.rand(1, device=device))\n",
    "                        \n",
    "                    elif i % 3 == 1:\n",
    "                        # Crop transform: Take center crop and resize back\n",
    "                        # Helps focus on central image content\n",
    "                        b, c, h, w = images.shape\n",
    "                        crop_size = int(0.925 * min(h, w))\n",
    "                        transformed_images = transforms.functional.center_crop(images, crop_size)\n",
    "                        transformed_images = F.interpolate(transformed_images, (h, w), \n",
    "                                                         mode='bilinear', align_corners=False)\n",
    "                        \n",
    "                    else:\n",
    "                        # Brightness transform: Add random noise\n",
    "                        # Helps with robustness to lighting variations\n",
    "                        transformed_images = images + 0.05 * torch.randn((batch_size, 1, 1, 1), \n",
    "                                                                       device=device)\n",
    "                        transformed_images = torch.clamp(transformed_images, -3, 3)\n",
    "                    \n",
    "                    outputs = model(transformed_images)\n",
    "                    probs = F.softmax(outputs, dim=1)\n",
    "                    ensemble_probs += probs\n",
    "            \n",
    "            # Average predictions across all variants\n",
    "            total_variants = len(ensemble) * (num_tta + 1)\n",
    "            ensemble_probs /= total_variants\n",
    "            \n",
    "            # Get final predictions\n",
    "            _, predicted = ensemble_probs.max(1)\n",
    "            \n",
    "            # Store batch results\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_ids.extend(image_ids.cpu().numpy())\n",
    "            \n",
    "            # Print progress every 10 batches\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"Processed {batch_idx + 1}/{len(test_loader)} batches\")\n",
    "    \n",
    "    print(\"\\nPrediction complete!\")\n",
    "    print(f\"Total predictions made: {len(all_predictions)}\")\n",
    "    return all_predictions, all_ids\n",
    "\n",
    "def load_test_data(test_file=\"./data/cifar-10-python/cifar_test_nolabel.pkl\"):\n",
    "    \"\"\"\n",
    "    Load and process test data, ensuring correct format for model input.\n",
    "    \n",
    "    This function:\n",
    "    1. Loads test data from pickle file\n",
    "    2. Handles different possible data formats:\n",
    "       - Flat (N, 3072)\n",
    "       - NHWC (N, 32, 32, 3)\n",
    "       - NCHW (N, 3, 32, 32)\n",
    "    3. Converts to required NCHW format\n",
    "    \n",
    "    Args:\n",
    "        test_file: Path to test data pickle file\n",
    "    Returns:\n",
    "        test_images: Processed images in NCHW format\n",
    "        test_ids: Corresponding image IDs\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Loading and Processing Test Data ===\")\n",
    "    print(f\"Loading from file: {test_file}\")\n",
    "    \n",
    "    with open(test_file, 'rb') as f:\n",
    "        test_dict = pickle.load(f, encoding='bytes')\n",
    "    \n",
    "    test_images = test_dict[b'data']\n",
    "    test_ids = test_dict[b'ids']\n",
    "    \n",
    "    print(\"\\nInitial data shapes:\")\n",
    "    print(f\"Images: {test_images.shape}\")\n",
    "    print(f\"IDs: {test_ids.shape}\")\n",
    "    \n",
    "    # Process data format\n",
    "    if len(test_images.shape) == 2:\n",
    "        print(\"\\nDetected flat format (N, 3072)\")\n",
    "        print(\"Reshaping to NCHW format (N, 3, 32, 32)...\")\n",
    "        test_images = test_images.reshape(-1, 3, 32, 32)\n",
    "        \n",
    "    elif len(test_images.shape) == 4:\n",
    "        if test_images.shape[1] != 3:\n",
    "            print(\"\\nDetected NHWC format (N, 32, 32, 3)\")\n",
    "            print(\"Converting to NCHW format...\")\n",
    "            test_images = np.transpose(test_images, (0, 3, 1, 2))\n",
    "        else:\n",
    "            print(\"\\nData already in NCHW format\")\n",
    "    \n",
    "    print(\"\\nFinal data shapes:\")\n",
    "    print(f\"Images: {test_images.shape}\")\n",
    "    print(f\"IDs: {test_ids.shape}\")\n",
    "    return test_images, test_ids\n",
    "\n",
    "class CIFAR10TestDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class for CIFAR-10 test data.\n",
    "    Handles loading and preprocessing of test images with optional transforms.\n",
    "    \n",
    "    Args:\n",
    "        data: Test image data in NCHW format\n",
    "        ids: Corresponding image IDs\n",
    "        transform: Optional transforms to apply to images\n",
    "    \"\"\"\n",
    "    def __init__(self, data, ids, transform=None):\n",
    "        self.data = data  # Image data\n",
    "        self.ids = ids    # Image IDs\n",
    "        self.transform = transform  # Optional transforms\n",
    "        print(f\"Initialized test dataset with {len(data)} images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Convert numpy array to float tensor and ensure NCHW format\n",
    "        image = torch.from_numpy(self.data[idx]).float()\n",
    "        \n",
    "        # Apply any specified transforms (e.g. normalization)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        image_id = self.ids[idx]\n",
    "        return image, image_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "# Step 7.5: Plotting Functions \n",
    "#############################\n",
    "def plot_training_history(train_losses, train_accs, val_losses, val_accs, save_path=None):\n",
    "    \"\"\"Plot the training and validation history\"\"\"\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    \n",
    "    # Plot losses\n",
    "    ax1.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
    "    ax1.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
    "    ax1.set_title('Loss Curves')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot accuracies\n",
    "    ax2.plot(epochs, train_accs, 'b-', label='Training Accuracy')\n",
    "    ax2.plot(epochs, val_accs, 'r-', label='Validation Accuracy')\n",
    "    ax2.set_title('Accuracy Curves')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.set_ylim(50, 100)\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_final_metrics(final_val_acc, param_count, classes_correct=None, save_path=None):\n",
    "    \"\"\"\n",
    "    Create a simple visualization of the final metrics\n",
    "    \n",
    "    Args:\n",
    "        final_val_acc: Final validation accuracy\n",
    "        param_count: Number of parameters in the model\n",
    "        classes_correct: Optional dictionary of per-class accuracies\n",
    "        save_path: Path to save the figure (optional)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Create a text-based summary at the top\n",
    "    ax.text(0.5, 0.95, 'CIFAR-10 Model Performance Summary', \n",
    "            fontsize=16, weight='bold', ha='center', transform=ax.transAxes)\n",
    "    ax.text(0.5, 0.89, f'Model Size: {param_count:,} parameters', \n",
    "            fontsize=14, ha='center', transform=ax.transAxes)\n",
    "    ax.text(0.5, 0.83, f'Validation Accuracy: {final_val_acc:.2f}%',\n",
    "            fontsize=14, ha='center', transform=ax.transAxes, color='#d62728' if final_val_acc > 85 else 'black')\n",
    "    \n",
    "    # Create a bar chart for class-specific accuracies if provided\n",
    "    if classes_correct is not None:\n",
    "        class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                      'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "        accuracies = [classes_correct.get(i, 0) for i in range(10)]\n",
    "        \n",
    "        # Plot class accuracies as a bar chart\n",
    "        y_pos = np.arange(len(class_names))\n",
    "        bars = ax.barh(y_pos, accuracies, color='skyblue')\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(class_names)\n",
    "        ax.set_xlim(0, 100)\n",
    "        ax.set_xlabel('Accuracy (%)')\n",
    "        ax.set_title('Per-Class Accuracy')\n",
    "        \n",
    "        # Add accuracy values on the bars\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            ax.text(width + 1, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{accuracies[i]:.1f}%', va='center')\n",
    "    else:\n",
    "        # If no class accuracies, create a simplified summary visual\n",
    "        ax.axis('off')  # Turn off axes\n",
    "        \n",
    "        # Create a green box for accuracy ≥ 85%\n",
    "        if final_val_acc >= 85:\n",
    "            ax.text(0.5, 0.5, f\"Validation\\nAccuracy\\n{final_val_acc:.2f}%\", \n",
    "                   fontsize=24, weight='bold', ha='center', va='center',\n",
    "                   transform=ax.transAxes, \n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightgreen', alpha=0.5))\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f\"Validation\\nAccuracy\\n{final_val_acc:.2f}%\", \n",
    "                   fontsize=24, weight='bold', ha='center', va='center',\n",
    "                   transform=ax.transAxes, \n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightblue', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "    \n",
    "\n",
    "def plot_class_distribution(predictions, save_path=None):\n",
    "    \"\"\"Plot the distribution of predicted classes\"\"\"\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                  'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    \n",
    "    # Count occurrences of each class\n",
    "    class_counts = np.bincount(predictions, minlength=10)\n",
    "    \n",
    "    # Create horizontal bar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    y_pos = np.arange(len(class_names))\n",
    "    ax.barh(y_pos, class_counts, color='skyblue')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(class_names)\n",
    "    ax.invert_yaxis()  # Labels read top-to-bottom\n",
    "    ax.set_xlabel('Number of Predictions')\n",
    "    ax.set_title('Distribution of Predicted Classes')\n",
    "    \n",
    "    # Add count labels to the bars\n",
    "    for i, v in enumerate(class_counts):\n",
    "        ax.text(v + 10, i, str(v), va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Main Execution Flow\n",
    "\n",
    "This section orchestrates the complete training and prediction pipeline by:\n",
    "\n",
    "1. Model Creation and Training\n",
    "   - Initializes optimized ResNet architecture with SE blocks\n",
    "   - Applies advanced training techniques like SWA and EMA\n",
    "   - Uses cosine learning rate scheduling with warmup\n",
    "   - Monitors and validates model performance\n",
    "\n",
    "2. Test Data Processing \n",
    "   - Handles multiple input data formats (NHWC, NCHW)\n",
    "   - Applies consistent preprocessing and augmentation\n",
    "   - Uses efficient data loading with pinned memory\n",
    "   - Implements parallel processing for speed\n",
    "\n",
    "3. Ensemble Prediction\n",
    "   - Combines predictions from multiple model checkpoints\n",
    "   - Applies test-time augmentation for robustness\n",
    "   - Uses weighted averaging of model outputs\n",
    "   - Handles prediction uncertainty\n",
    "\n",
    "4. Submission Generation\n",
    "   - Creates properly formatted submission file\n",
    "   - Includes confidence scores for predictions\n",
    "   - Validates output format and constraints\n",
    "   - Implements error checking and logging\n",
    "\n",
    "The pipeline is designed to:\n",
    "- Maximize prediction accuracy through model ensembling\n",
    "- Maintain efficient processing through optimized data handling\n",
    "- Ensure robustness through multiple augmentation strategies\n",
    "- Provide detailed logging for monitoring and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n=== Starting Main Execution Pipeline ===\")\n",
    "\n",
    "# Create model with optimized architecture\n",
    "print(\"\\nInitializing model architecture...\")\n",
    "print(\"Using configuration:\")\n",
    "print(\"- 3-5-3 block structure for balanced depth\")\n",
    "print(\"- 40 initial channels for good feature extraction\")\n",
    "print(\"- Squeeze-and-Excitation for attention\")\n",
    "print(\"- 0.2 dropout for regularization\")\n",
    "\n",
    "model = OptimizedResNet(\n",
    "    block=BasicBlock,\n",
    "    num_blocks=[3, 5, 3],    # Balanced depth with more middle blocks\n",
    "    initial_channels=40,      # Increased channels for better feature extraction\n",
    "    use_se=True,             # Add attention mechanism\n",
    "    se_reduction=8,          # SE reduction ratio\n",
    "    drop_rate=0.2            # Dropout for regularization\n",
    ").to(device)\n",
    "\n",
    "# Verify model size constraints\n",
    "param_count = count_parameters(model)\n",
    "print(f\"\\nModel Architecture Summary:\")\n",
    "print(f\"Total trainable parameters: {param_count:,}\")\n",
    "\n",
    "if param_count > 5_000_000:\n",
    "    raise ValueError(f\"Model exceeds parameter limit: {param_count:,} > 5,000,000\")\n",
    "\n",
    "# Train model with advanced techniques\n",
    "print(\"\\nStarting model training phase...\")\n",
    "model, swa_model, ema, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=250  # Extended training for better convergence\n",
    ")\n",
    "\n",
    "# Process test data\n",
    "print(\"\\nLoading and preparing test data...\")\n",
    "test_images, test_ids = load_test_data()\n",
    "\n",
    "# Create optimized test data pipeline\n",
    "print(\"\\nSetting up test data pipeline...\")\n",
    "print(\"- Using batch size 256 for efficient processing\")\n",
    "print(\"- Enabling 4 worker processes for parallel loading\")\n",
    "print(\"- Using pinned memory for faster GPU transfer\")\n",
    "\n",
    "test_dataset = CIFAR10TestDataset(test_images, test_ids, transform=test_transform)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=256,      # Efficient batch size\n",
    "    shuffle=False,       # Maintain order for predictions\n",
    "    num_workers=4,       # Parallel data loading\n",
    "    pin_memory=True      # Faster GPU transfer\n",
    ")\n",
    "\n",
    "# Initialize ensemble models\n",
    "print(\"\\nPreparing model ensemble...\")\n",
    "\n",
    "# Load best standard model checkpoint\n",
    "print(\"Loading best standard model...\")\n",
    "best_model = OptimizedResNet(\n",
    "    block=BasicBlock,\n",
    "    num_blocks=[3, 5, 3],\n",
    "    initial_channels=40,\n",
    "    use_se=True,\n",
    "    se_reduction=8,\n",
    "    drop_rate=0.0  # Disable dropout for inference\n",
    ").to(device)\n",
    "best_model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "# Load best EMA model checkpoint\n",
    "print(\"Loading EMA model...\")\n",
    "ema_model = OptimizedResNet(\n",
    "    block=BasicBlock,\n",
    "    num_blocks=[3, 5, 3],\n",
    "    initial_channels=40,\n",
    "    use_se=True,\n",
    "    se_reduction=8,\n",
    "    drop_rate=0.0\n",
    ").to(device)\n",
    "ema_model.load_state_dict(torch.load(\"best_ema_model.pth\"))\n",
    "\n",
    "# Prepare SWA model for inference\n",
    "print(\"Preparing SWA model...\")\n",
    "swa_model.module.drop_rate = 0.0  # Disable dropout\n",
    "\n",
    "# Create ensemble for robust predictions\n",
    "print(\"Combining models into ensemble...\")\n",
    "ensemble = [best_model, ema_model, swa_model]\n",
    "\n",
    "# Generate predictions using ensemble and TTA\n",
    "print(\"\\nGenerating predictions with ensemble and test-time augmentation...\")\n",
    "all_predictions, all_ids = predict_with_enhanced_tta(ensemble, test_loader, num_tta=5)\n",
    "\n",
    "# Create and save submission file\n",
    "print(\"\\nPreparing submission file...\")\n",
    "df_submission = pd.DataFrame({\n",
    "    \"ID\": all_ids,\n",
    "    \"Labels\": all_predictions\n",
    "})\n",
    "df_submission = df_submission.sort_values(by=\"ID\")  # Sort by ID for consistency\n",
    "csv_filename = \"submission.csv\"\n",
    "df_submission.to_csv(csv_filename, index=False)\n",
    "print(f\"Submission saved to: {csv_filename}\")\n",
    "\n",
    "print(\"\\n=== Pipeline Complete ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9: Final Evaluation and Submission\n",
    "In this final step, we:\n",
    "1. Load our best models (regular, EMA, and SWA) for ensemble prediction\n",
    "2. Set dropout to 0 since we're doing inference\n",
    "3. Use Test Time Augmentation (TTA) with 5 different augmentations\n",
    "4. Create ensemble predictions by averaging outputs from all models\n",
    "5. Generate submission file with predictions\n",
    "6. Plot the distribution of predicted classes\n",
    "7. Print final model statistics including parameter count and validation accuracy\n",
    "\n",
    "The ensemble approach combines predictions from multiple models to reduce variance\n",
    "and improve robustness. TTA further improves reliability by averaging predictions\n",
    "across different augmented versions of each test image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot training and validation metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_training_metrics(train_losses, train_accs, val_losses, val_accs):\n",
    "    \"\"\"\n",
    "    Plot training and validation metrics over epochs.\n",
    "    Creates two subplots:\n",
    "    1. Loss curves\n",
    "    2. Accuracy curves\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    # Plot losses\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot accuracies \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accs, 'b-', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_accs, 'r-', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_metrics.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_class_distribution(predictions, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot distribution of predicted classes.\n",
    "    Creates a bar plot showing count of predictions for each class.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    class_counts = np.bincount(predictions)\n",
    "    \n",
    "    # Create bar plot\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.bar(range(10), class_counts)\n",
    "    plt.title('Distribution of Predicted Classes')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(True, axis='y')\n",
    "    \n",
    "    # Add count labels on top of each bar\n",
    "    for i, count in enumerate(class_counts):\n",
    "        plt.text(i, count, str(count), ha='center', va='bottom')\n",
    "    \n",
    "    # Add pie chart\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.pie(class_counts, labels=range(10), autopct='%1.1f%%')\n",
    "    plt.title('Class Distribution (Pie Chart)')\n",
    "    \n",
    "    # Add horizontal bar plot\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.barplot(x=class_counts, y=range(10))\n",
    "    plt.title('Horizontal Class Distribution')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Class')\n",
    "    \n",
    "    # Add KDE plot\n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.kdeplot(data=predictions)\n",
    "    plt.title('Density Distribution of Classes')\n",
    "    plt.xlabel('Class')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_learning_rate_schedule(learning_rates, save_path='lr_schedule.png'):\n",
    "    \"\"\"\n",
    "    Plot learning rate schedule over epochs\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, len(learning_rates) + 1), learning_rates)\n",
    "    plt.title('Learning Rate Schedule')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predictions, save_path='confusion_matrix.png'):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix for model predictions\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# Call plotting functions if history metrics are available\n",
    "try:\n",
    "    train_losses, train_accs, val_losses, val_accs = history\n",
    "    plot_training_metrics(train_losses, train_accs, val_losses, val_accs)\n",
    "    print(\"Training metrics plots saved as training_metrics.png\")\n",
    "    \n",
    "    if 'learning_rates' in locals():\n",
    "        plot_learning_rate_schedule(learning_rates)\n",
    "        print(\"Learning rate schedule plot saved as lr_schedule.png\")\n",
    "        \n",
    "    if 'y_true' in locals() and 'y_pred' in locals():\n",
    "        plot_confusion_matrix(y_true, y_pred)\n",
    "        print(\"Confusion matrix plot saved as confusion_matrix.png\")\n",
    "        \n",
    "except NameError:\n",
    "    print(\"Training history not found. Skipping training metrics plots.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11145869,
     "sourceId": 93057,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
